\subsection{Разработка тонального класификатора}
    % Архитектура проекта
    % Описать зависимости, а также что требуется реализовать.
    % Для решения задачи сентиментального анализа требуется:
    %   - классификатор (LibSVM)
    %   - модули обработки сообщений (Mystem + тональные префиксы + списки стоп слов)
    %
    % Выбор языка для реализации приложения
    %   - Python
    % хранения коллекций сообщений сети Twitter, а также вспомогательных данных:
    %   - База данных
    В качестве основы для разработки приложения был выбран язык {\it Python},
    ввиду следующих особенностей:
    \begin{enumerate}
        \item Отсутствие временных ограничений на обработку сообщений,
            классификацию;
        \item Возможность быстро подстраиваться под изменение архитектуры
            проекта и введения новых возможностей;
        \item Наличие библиотеки LibSVM\cite{svmClassifier} реализующей
            классификацию методом <<Опорных Векторов>>.
    \end{enumerate}

    Что касается вопроса хранения коллекций и вспомогательной информации
    для решения задачи классификации, для этих целей используется СУБД
    {\it PostgreSQL}. Такой выбор обусловлен удобным интерфейсом взаимодействия
    через сценарии языка {\it Python}, а также возможностью удобного консольного
    администрирования хранилища. Как и в случае с выбором языка для реализации
    задачи, на выбор хранилища не накладываются временные ограничения.

    Под разработкой проекта понимается реализация сценариев на языке Python,
    для выполнения следующих подздачач:
    %
    % Описать в формате потока, какие действия требуются чтобы произвести
    % классификацию с оценкой или без нее.
    %
    \begin{enumerate}
        \item Подготовка коллекций -- импорт XML данных в хранилище;
        \item Построение модели на основе обучающей коллекции;
        \item Применение модели к данным тестовой коллекции;
        \item Экспорт размеченных классификатором сообщений из хранилища в XML формат;
        \item Вычисление оценки качества работы модели.
    \end{enumerate}

    \subsubsection{Обработка сообщений сети Twitter}
    % Описать про модуль обработки.
    % Рассказать про применение тональных префиксов, удаление стоп слов.
    % А также, что все начинается с этапа лемматизации сообщения.
    % Что такое слово? -- последовательность символов, разделенная пробелами.
    Прежде чем перейти к описанию процесса преобразования, введем следующие
    понятия:
    \begin{itemize}
        \item {\bf Слово} --- это последовательность симоволов, которая ограничена
            пробельными символами, либо символами перевода строки.
        \item {\bf Терм} --- слова сообщения, к которым либо была применена
            лемматизация, либо применение лемматизации не требуется.
    \end{itemize}

    % рассказать про модуль в проекте. Описываем msg.py (можно просто предоставить
    % диаграмму UML для одного класса).

    Процесс обработки сообщений начинается с этапа разбиния всех слов сообщения
    на следующие классы (согласно п. ...):
    \begin{itemize}
        \item Имена пользователей сети \twitter --- термы с префиксом <<@>>;
        \item Хэштеги (от англ. {\it Hashtags}) --- термы с префиксом <<\#>>.
        \item Символы <<Ретвита>> --- термы со значением <<RT>>;
        \item Ссылки на ресурсы сети Интернет --- {\it URL\hspace{1pt}}-адреса;
        \item Основные слова --- множество слов, не вошедших ни в один из четырех
            выше перечисленных классов.
    \end{itemize}

    Код программы, отвечающий за выбор класса, к которому относится каждое из
    слов сообщения, представлен в листинге \ref{lst:classSelection}.

    \lstset{style=python}
    \lstinputlisting[caption="Определение класса для каждого из слов сообщения",
        label={lst:classSelection}]{parts/code/dev/classSelection.py}

    Все слова, не относящиеся ко множеству {\it основных слов}, не требуют
    дальнейшей лемматизации. Поэтому, ввиду выше введенных определений, слова
    этих множеств можно считать термами.

    % Лемматизация
    На следующем этапе обработки сообщения выполняется лемматизация основных слов.
    Результатом этого этапа должны стать леммы, представлюящие собой последовательность
    буквенных символов.
    Другими словами, леммы должны быть очищены от знаков препинания, эмотиконов,
    и т.п.

    Для преобразования слова в лемму, используется пакет {\it Mystem} компании
    {\it Yandex} \cite{mystem}.
    Такой пакет предоставляет одноименный класс {\it Mystem}, объект на основе
    которого используется для лемматизации текстовых сообщений.
    Лемматизация производится на основе словарей русского языка, которые
    добавляются в качестве компонента к пакету при первом его использовании.

    Для, того чтобы игнорировать знаки препинания, а также эмотиконы которые
    могут встречаться в конце слов, пакет предусматривает в качестве аргумента
    параметр {\it entire\_input} со значением {\it false}.
    Лемматизация основных слов сообщения приведена в листинге \ref{lst:lemmatization}.

    \lstset{style=python}
    \lstinputlisting[caption="Лемматизация основных слов сообщения",
        label={lst:lemmatization}]{parts/code/dev/lemmatize.py}

    % Получили список термов. Используем эти термы для обучения классификатора.
    После того как список термов получен, необходимо произвести векторизацию
    сообщения, необходимую для подготовки обучающих данных SVM классификатора.

    \subsubsection{Использование LibSVM для классификации методом <<Опорных векторов>>}
    % Описать про использование SVM классификатора

    \subsubsection{Вспомогательные признаки классификации}
    % Модуль добавления признаков в векторизацию сообщений.

\subsection{Разработка вспомогательных инструментов}
% Выбор языка для реализации вспомогательных инструментов приложения
%   - Python
В роли вспомогательных инструментов выступают компоненты, которые в совокупности
решают задачу построения тонального лексикона на основе сообщений сети \twitter.
Реализация сценариев осуществляется посредством языка {\it Python}.

    \subsubsection{Прием текстовых сообщений сети Twitter}

    \subsubsection{Создание лексиконов методом определения тональности словосочетаний}

