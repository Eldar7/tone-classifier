\newpage
\section{Описание подхода к решению задачи тонального анализа сообщений сети Twitter}
    \label{sec:buildingApproachDescription}
    % Описать классификатор, который планируется использовать
    Основным и единственным параметром для классификаторов на основе методов машинного
    обучения являются вектора, описывающие исходные сообщения.
    Рассмотрим процесс преобразования сообщений в вектор, а также добавим
    дополнительные признаки которые бы способствовали повышению качества
    классификации.

    \subsection{Обработка сообщений}
    \label{sec:buildingMsgProcessing}
    % Векторизация, ее параметры
    Пусть имеется произвольная коллекция сообщений сети \twitter. Процесс
    обработки сообщений этой коллекции состоит из выполнения следующих этапов:
    \begin{enumerate}
        \item Лемматизация слов сообщений с целью получения списка термов;

        \item Все термы сообщения можно разделить на два класса: основные и
            дополнительные. Ко второму классу относятся следующие термы:
            \begin{itemize}
                \item Символы <<Ретвита>> --- термы со значением <<RT>>;
                \item Ссылки на ресурсы сети Интернет --- {\it URL\hspace{1pt}}-адреса;
                \item Имена пользователей сети \twitter --- термы с префиксом <<@>>;
                \item Хэштеги (от англ. {\it Hashtags}) --- термы с префиксом <<\#>>.
            \end{itemize}
            Все остальные термы относятся к классу основных, и на текущем этапе
            термы этого класса остаются в сообщении. Среди множества дополнительных
            термов, в сообщении остаются только хэштеги и {\it URL\hspace{1pt}}-адреса;

        \item Применение предварительно составленного {\it списка стоп слов} ---
            это термы, которые должны быть исключены из сообщения.
            % Описать подробнее (После)
        \item Замена некоторых биграмм и униграмм на тональные префиксы.
            % Описать подробнее (После)
    \end{enumerate}

    Рассмотрим последний пункт обработки сообщения подробнее.
    Для выполнения этого этапа, предполагается что предварительно составлен
    список пар $L_{tone} = {\langle t, s\rangle}$, где $t$ -- терм, а $s$ --
    тональная оценка (<<+>> или <<-->>). На этом этапе, для каждого терма сообщения $t_i \in L_{tone}$
    выполняется замена на соответствующую оценку $s$, которая становится префиксом
    следующего терма $t_{i+1}$. Пример преобразования:
    \begin{center}
        \it
        Сейчас \underline{хорошо} работать \underline{не} то что раньше.

        Сейчас +работать --то что раньше.
    \end{center}

    Среди описанных выше этапов обработки сообщений, обязательным и неизменным
    является только лемматизация слов сообщений. Использование и настройки
    остальных этапов могут быть изменены в зависимости от предпочтений
    пользователя.

    % Написать про tf-idf и про дополнительный словарь
    Для получения весовых коэффициентов термов, предполагается использовать меру {\it tf-idf}.
    Дополнительно рассмотрим {\it искусственное} расширение исходной
    обучающей коллекции посредством информации о числе вхождений большинства
    популярных термов в корпус объемом $10^6$ сообщений. Такое расширение
    позволит оценить частоты термов на основе коллекции потенциально
    большего объема чем объем исходной обучающей коллекции.

    \subsection{Вспомогательные признаки классификации}
    \label{sec:buildingAdditionalFeatures}
    % В этот раздел вносим признаки, которые добавлялись к основной векторизации
    Помимо термов, составляющих вектор сообщения, в векторизацию предполагается внести
    все признаки, перечисленные в п. \ref{sec:additionalFeatures}:
    \begin{itemize}
        \item Преобразование эмотиконов сообщения в числовой коэффициент.
        Предварительно составляются два множества эмотиконов: негативные и
        положительные. Для каждого множества определяется $C$ -- суммарное число
        вхождений его элементов в рассматриваемое сообщение.
        Результирующий числовой коэффициент вычисляется по формуле: $C_+ - C_-$;

        \item Подсчет количества термов, записанных в верхнем регистре;

        \item Подсчет числа знаков препинания: <<?>>, <<...>>, <<!>>;

        \item Относительно каждого из предварительно составленных лексиконов, вычисляется
            сумма численных коэффициентов лексикона для термов входящих в рассматриваемое
            сообщение. Если терм отсутствует в лексиконе, то в качестве коэффициента рассматривается
            нулевое значение.

            Дополнительно производится нормализация полученного значения в
            диапазоне $\left[ -1, 1 \right]$ на основе следующего преобразования:
            \begin{numcases}{}
                s = 1 - e^{|x|}, x > 0  {\label{eq:norm1}}  \\
                s = - (1 - e^{|x|}), x < 0 {\label{eq:norm2}}
            \end{numcases}
    \end{itemize}
    \subsection{Коллекции данных для обучения}
    % Здесь рассказываем про коллекции, которые использовались несбалансированные для обучения коллекции
    Для обучения классификатора предполагается использовать соответствующие коллекции
    данных соревнований {\it SentiRuEval}. Поскольку в предоставляемых данных
    число тональных сообщений существенно уступает объему класса нейтральных сообщений,
    то дополнительно планируется создать сбалансированную обучающую коллекцию.
    В работе \cite{diploma2015}, применительно к классификаторам типа {\it Наивного Байеса}
    и {\it SVM}, отмечается существенный прирост качества при использовании
    коллекций сбалансированного типа.

    % Про балансировку коллекций в том числе.
    Предоставляемые коллекции для обучения достаточно велики (см. таблицу
    \ref{table:trainTableStat}) по объему для проведения ручной балансировки. Для решения
    подобной задачи можно воспользоваться готовыми корпусами, в котором сообщения
    автоматически распределены на две тональные группы: положительные и
    негативные. В целях исследования улучшения качества, в качестве источника
    дополнительных тональных сообщений можно использовать корпус коротких
    сообщений сети \twitter, предоставляемый Ю. Рубцовой \cite{rubtsovaCollection}.
    Характеристики такого корпуса представлены в таблице \ref{table:rubtsovaCorpusSpecs}.

    \begin{table}[H]
    \centering
    \caption{Параметры корпуса коротких сообщений сети \twitter, Ю.Рубцова}
    \label{table:rubtsovaCorpusSpecs}
    \begin{tabular}{|c|c|}
    \hline
    Коллекция & Число сообщений \\ \hline
    {\it positive} & 114\hspace{3pt}991 \\ \hline
    {\it negative} & 111\hspace{3pt}923 \\ \hline
    \end{tabular}
    \end{table}

    % (Как производить балансировку)
    Среди всех сообщений каждого класса корпуса коротких сообщений, необходимо
    отобрать небольшой процент тех, которые являются наиболее эмоциональными.
    В общем случае, можно сказать, что требуется функция, которая бы на основе
    слов сообщения, а также эмоциональных коэффициентов каждого из слов,
    позволила бы оценить рассматриваемое предложение.

    Вычисление эмоциональных коэффициентов можно производить
    с использованием лексиконов, на основе подхода, рассмотренного в п. \ref{sec:soEvaluation}.
    Определение оценки сообщения можно произвести одним из следующих способов:
    \begin{itemize}
        \item Вычисление {\it суммы эмоциональных коэффициентов} всех входящих в сообщение слов;
        \item Вычисление {\it максимального коэффициента} среди всех слов сообщения.
    \end{itemize}

    Если полученные значения рассматривать в формате абсолютных величин, то
    введение нижнего порогового значения позволяет отобрать наиболее подходящие
    сообщения. Таким образом можно получить сообщения, которые являются
    наиболее предпочтительными для балансировки обучающих коллекций.
