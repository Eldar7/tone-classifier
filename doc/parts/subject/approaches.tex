\subsection{Подходы к решению задачи тональной классификации с использованием лексиконов}
    % Добавить обзор статей
    \subsubsection{Автоматическое порождение тональных лексиконов}
    В работе \cite{severyn} описан способ построения лексикона
    на основе метода <<удаленного контроля>>. В качестве исходных сообщений,
    авторы подхода использовали корпус сообщений сети \twitter, содержащий
    для каждого информации метки мнений ({\it positive} и {\it negative}).
    Такие метки легли в основу обучения контроля полярности классификатора.

    % Описание модели (постановка задачи, раскрытие термина)
    Задача контроля полярности ставится следующим образом. Пусть имеется
    размеченные данные $ \{{\bf x}_i, {\bf y}_i \}_{i=1}^{n}$, на основе
    которых требуется необходимо построить функцию принятия решения
    $f({\bf x}) \to {\bf y}$, которая бы на основе входных параметров
    определяла бы результирующую метку сообщения.
    В частности, авторы использовали линейную модель SVM классификатора, с
    функцией предсказания следующего вида:
    \begin{equation}
        f = sign(w^T{\bf x} + b)
    \end{equation}

    Где $w$ -- весовые коэффициенты, полученные на основе обучающей коллекции;
    $b$ -- поправочный коэффициент.

    % Алгоритм построения модели
    Авторы статьи предлагают следующий подход автоматического построения
    лексикона и его использования для создания классификационной модели:
    \begin{enumerate}
        \item Составление неразмеченного корпуса сообщений сети \twitter $C$.
        \item Для каждого сообщения $t_i \in C$ использовать подсказки
            (хэштеги, эмотиконы) для получения метки ({\it positive} и {\it negative})
            $y_i \in \{-1; +1\}$. Использование эмотиконов вида <<:-)>>, <<:-(>>
            в качестве индикатора выражения автора сообщения в целом.
        \item Извлечение биграмм и униграмм особенности сообщения $t_i$ в
            вектор ${\bf x}_i \in R^{|L|}$, где $L$ -- лексикон, состоящий из
            термов формата биграмм и униграмм;
        \item Построить классификационную модель ${\bf w}$ на основе корпуса
            $C = \{{\bf x}_i, {\bf y}_i \}_{i=1}^{N}$ следующим образом:
        \begin{equation}
            {\bf w} = \sum\limits_{i=1}^{N}\alpha_i y_i {\bf x}_i
        \end{equation}
        Здесь ${\bf x}_i$ выступают в качестве опорных векторов; $y_i$ -- их метки;
        $\alpha_i$ -- параметр краевой задачи, который вносит вклад в
        $w$ в случае когда положителен.
        \item Каждый компонент $w_j$ обученной модели $w$, соответствует компоненту $l_i$
            лексикона $L$, что устанавливает связи с ассоциативной оценкой.
    \end{enumerate}

    % Алгоритм построения лексикона
    Используемый лексикон составлен на основе \twitter корпуса {\it Emoticon140}.
    Метки для корпуса расставлялись на основе эмотиконов, содержащихся в
    тексте сообщений.
    Так, сообщения содержащие эмотиконы типа <<:)>> считались положительными,
    а <<:(>> -- отрицательными.
    Объем корпуса составляет $1.6$ млн. сообщений с одинаковым распределением
    положительных и негативных сообщений.

    Для составления лексикона используется подход на основе вычисления
    точечной меры взаимоинформации (см. п. \ref{sec:soEvaluation}).
    Дополнительно авторами были составлены собственные лексиконы: MPQA, BingLiu, NRC.
    На этапе предварительного тестирования и настройки модели, отмечается прирост
    качества при увеличении числа используемых лексиконов.

    % Результаты
    Подход демонстрирует хорошие результаты качества работы классификационной
    модели. На соревнованиях {\it Semeval-2014} такой подход занял второе
    место.
    Применительно к коллекциям $SMS$ и $Twitter$, оценка качества работы на
    основе $F-$меры колеблется в диапазоне 66.8 -- 71\%.

    \subsubsection{<<State-of-the-art>> подход к решению задачи
        сентиментального анализа (Saif M. Mohammad, Svetlana Kiritchenko, Xiaodan Zhu)}

    Статья \cite{modernApproach} предлагает способы построения {\it SVM}
    классификаторов для решения следующих задач классификации:
    \begin{itemize}
        \item Определения тональной оценки для всего сообщения в целом;
        \item Выявления тональности термов сообщения.
    \end{itemize}

    % Описание подхода (только для случая оценки сообщения в целом)
        % Идея с автоматической генерацией лексикона
    Ключевой идеей повышения качества классификации являются лексиконы,
    которые созданы автоматически на основе коллекции сети \twitter.
    Для этого, авторы разделили все сообщения корпуса на тональные классы с
    помощью такой метаинформации в сообщениях, как хэштеги.
    Для этого были составлены два множества хэштегов: {\it positive} и
    {\it negative}.

    Объем коллекции, на основе которой составлен лексикон, составляет $775$
    тыс. сообщений. Для распределения сообщений на классы, авторы использовали
    следующую логику:
    \begin{enumerate}
        \item Если в сообщении встречался хотя бы один хэштег из множества positive, то
            сообщение считается положительным;
        \item Если в сообщении встречается хотя бы один хэштег из negative множества, то
            сообщение считается отрицательным.
    \end{enumerate}

    Для построения лексиконов, авторы использовали метод <<тональности словосочетаний>>
    (см. п. \ref{sec:soEvaluation}, формула \ref{eq:so}) \cite{lexiconSO}.

    В качестве классификатора, авторы использовали SVM с линейным ядром, и
    параметром штрафной функции $C = 5\cdot 10^{-3}$.
    Векторизация сообщения включала в себя набор дополнительных признаков:
    % Используемые признаки
    \begin{itemize}
        \item {\bf Учет регистра:} количество слов, записанных в верхнем регистре;
        \item {\bf Учет хэштегов:} число входящих в сообщение хэштегов (слов с префиксом <<\#>>);
        \item {\bf Символьные $n$-граммы:} присутствие или отсутствие последовательности
            подряд идущих одинаковых символов длиной в 3, 4, и 5 символов;
        \item {\bf На основе лексиконов:}
            Множество всех лексиконов включает в себя три лексикона, созданных
            в ручную ({\it NRC Emotion Lexicon, MPQA, Bing Liu Lexicon)}, а также
            два автоматически сгенерированных ({\it Hashtag Sentiment Lexicon,
            Sentiment140}). В качестве термов выступали биграммы, униграммы,
            Пусть $w$ -- рассматриваемый токен, $p$ -- полярность. Тогда,
            авторами были составлены следующие признаки:% функции
            \begin{itemize}
                \item Число токенов, для которых выполнено: $score(w, p) > 0$;
                \item Суммарное значение $\sum_{w \in tweet} score(w,p)$;
                \item Вычисление максимума $\max_{w \in tweet} score(w,p)$;
                \item Учет оценки последнего токена, при условии: $score(w,p) > 0$.
            \end{itemize}
        \item {\bf Пунктуация:}
            \begin{itemize}
                \item Подсчет числа последовательностей символов <<!>> и <<?>>,
                    а также подсчет случаев когда они оба символа встречаются в одной последовательности;
                \item Учет содержания знаков <<?>> или <<!>> в последнем терме.
            \end{itemize}
        \item {\bf Эмотиконы:}
            \begin{itemize}
                \item Присутствие или отсутствие положительных и негативных
                    эмотиконов в любой позиции сообщения;
                \item Признак, указывающий на наличие эмотикона (положительного
                    или негативного) в конце сообщения.
            \end{itemize}
        \item {\bf Удлиненные слова:} число слов, в которых символ повторяется
            более двух раз, например <<sooooo>>;
        \item {\bf Суффикс отрицания:} добавляет к слову суффикс {\it <<\_NEG>>},
            в случае, если перед ним имеется конструкция 'Отрицание +
            знак пунктуации'.
            Под отрицанием понимаются слова вида: {\it<<no>>}, {\it <<shouldn't>>}.
            В качестве знаков пунктуации рассматриваются символы:
            <<,>>, <<.>>, <<:>>, <<;>>, <<!>>, <<?>>.
            Пример преобразования:
            \begin{center}
                \it
                \underline{shouldn't,} perfect \\
                perfect\_NEG
            \end{center}
    \end{itemize}

    % Результаты
    Среди всех команд, принимавших участие в соревновании {\it SemEval-2013 'Detecting
    Sentiment in Twitter'}, описанный подход занял первое место как в задаче
    определения тональности отдельного терма, так и сообщения в целом.
    По задаче оценки термов, авторам подхода удалось добиться оценки
    $F_{score}$ = $69.02\%$. На задаче тонального анализа на уровне сообщения,
    лучшая оценка несколько выше: $88.93\%$.
