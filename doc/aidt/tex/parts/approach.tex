\section{Описание подхода}
    \label{sec:buildingApproachDescription}
    В области классификации сообщений методами машинного обучения, использование
    {\it SVM} классификатора (в сравнении с {\it Naive Bayes}) обусловлено результатами
    тестирования в \cite{svmAdvantages}, которые показывают преимущество SVM на униграммной
    модели обработки сообщений.\footnote{
        Использование униграммной модели упрощает процесс обработки сообщения с
        точки зрения добавления метаинформации, в том числе и на основе лексиконов.
        В текущем подходе все термы, содержащиеся во всех лексиконах, являются
        униграммами.
    }
    Для построения обучающей модели и предсказания
    тональности на ее основе, используется библиотека LibSVM \cite{svmClassifier}.

    \subsection{Обработка сообщений}
    \label{sec:buildingMsgProcessing}
    % Векторизация, ее параметры
    Процесс обработки сообщений коллекции сообщений состоит из следующих этапов:
    \begin{enumerate}
        \item Лемматизация слов сообщений с целью получения списка термов\footnote{
            Использование пакета Yandex Mystem:
            \url{http://tech.yandex.ru/mystem/}
            };

        \item Все термы сообщения можно разделить на два класса: {\it основные} и
            {\it дополнительные}.
            Ко второму классу относятся следующие термы:
            \begin{itemize}
                \item Символы <<Ретвита>> --- термы со значением <<RT>>;
                \item Ссылки на ресурсы сети Интернет --- {\it URL\hspace{1pt}}-адреса;
                \item Имена пользователей сети {\it Twitter} --- термы с префиксом <<@>>;
                \item Хэштеги --- термы с префиксом <<\#>>.
            \end{itemize}
            Все остальные термы относятся к классу {\it основных}, и на текущем этапе
            термы этого класса остаются в сообщении. Среди множества дополнительных
            термов, в сообщении остаются только хэштеги и {\it URL\hspace{1pt}}-адреса;
            Для получения весовых коэффициентов термов предполагается использовать меру {\it tf-idf}.

        \item Применение предварительно составленного {\it списка стоп слов} ---
            это термы, которые должны быть исключены из сообщения.
            % Описать подробнее (После)
        \item Замена некоторых биграмм и униграмм на тональные префиксы.
            Для выполнения этого этапа, предполагается что предварительно составлен
            список пар $L_{tone} = {\langle t, s\rangle}$, где $t$ -- терм, а $s$ --
            тональная оценка (<<+>> или <<-->>). На этом этапе, для каждого терма сообщения $t_i \in L_{tone}$
            выполняется замена на соответствующую оценку $s$, которая становится префиксом
            следующего терма $t_{i+1}$. Пример преобразования:
            \begin{center}
                \it
                Сейчас \underline{хорошо} работать, \underline{плохо} было раньше.

                Сейчас +работать, -было раньше.
            \end{center}
    \end{enumerate}

    %Среди описанных выше этапов обработки сообщений, обязательным и неизменным
    %является только лемматизация слов сообщений. Использование и настройки
    %остальных этапов могут быть изменены в зависимости от предпочтений
    %пользователя.
    % Написать про tf-idf и про дополнительный словарь
    %Дополнительно рассмотрим {\it искусственное} расширение исходной
    %обучающей коллекции посредством информации о числе вхождений большинства
    %популярных термов в корпус объемом $10^6$ сообщений. Такое расширение
    %позволит оценить частоты термов на основе коллекции потенциально
    %большего объема чем объем исходной обучающей коллекции.

    \subsection{Вспомогательные признаки классификации}
    \label{sec:buildingAdditionalFeatures}
    % В этот раздел вносим признаки, которые добавлялись к основной векторизации
    Помимо термов, составляющих вектор сообщения, предполагается внести
    следующие признаки:
    \begin{itemize}
        \item Преобразование эмотиконов сообщения в числовой коэффициент.
        Предварительно составляются два множества эмотиконов: отрицательные и
        положительные. Для каждого множества определяется $C$ -- суммарное число
        вхождений его элементов в рассматриваемое сообщение.
        Результирующий числовой коэффициент вычисляется по формуле: $C_+ - C_-$;

        \item Подсчет количества термов, записанных в верхнем регистре;

        \item Подсчет числа знаков препинания: <<?>>, <<...>>, <<!>>;

        \item Относительно каждого из предварительно составленных лексиконов, вычисляется
            сумма численных коэффициентов лексикона для термов входящих в рассматриваемое
            сообщение. Если терм отсутствует в лексиконе, то в качестве коэффициента рассматривается
            нулевое значение.

            Дополнительно производится нормализация полученного значения в
            диапазоне $\left[ -1, 1 \right]$ на основе следующего преобразования:
            \begin{numcases}{}
                s = 1 - e^{-|x|}, x > 0  {\label{eq:norm1}}  \\
                s = - (1 - e^{-|x|}), x < 0 {\label{eq:norm2}}
            \end{numcases}
    \end{itemize}
    \subsection{Коллекции данных для обучения}
    % Здесь рассказываем про коллекции, которые использовались несбалансированные для обучения коллекции
    Для обучения классификатора предполагается использовать соответствующие коллекции
    данных соревнований {\it SentiRuEval}. Поскольку в предоставляемых данных
    число тональных сообщений существенно уступает объему класса нейтральных сообщений,
    то дополнительно планируется создать сбалансированную обучающую коллекцию.
    В работе \cite{diploma2015}, применительно к классификаторам типа {\it Наивного Байеса}
    и {\it SVM}, отмечается существенный прирост качества при использовании
    коллекций сбалансированного типа.

    % Про балансировку коллекций в том числе.
    Предоставляемые коллекции для обучения достаточно велики (см. таблицу
    \ref{table:trainTableStat}) по объему для проведения ручной балансировки. Для решения
    подобной задачи можно воспользоваться готовыми корпусами, в котором сообщения
    автоматически распределены на две тональные группы: положительные и
    негативные. В целях исследования улучшения качества, в качестве источника
    дополнительных тональных сообщений можно использовать корпус коротких
    сообщений сети {\it Twitter}, предоставляемый Ю. Рубцовой \cite{rubtsovaCollection}.
    Характеристики такого корпуса представлены в таблице \ref{table:rubtsovaCorpusSpecs}.

    \begin{table}[H]
    \centering
    \caption{Параметры корпуса коротких сообщений сети {\it Twitter}, Ю.Рубцова}
    \label{table:rubtsovaCorpusSpecs}
    \begin{tabular}{|c|c|}
    \hline
    Коллекция & Число сообщений \\ \hline
    {\it positive} & 114\hspace{3pt}991 \\ \hline
    {\it negative} & 111\hspace{3pt}923 \\ \hline
    \end{tabular}
    \end{table}

    % (Как производить балансировку)
    Среди всех сообщений каждого класса корпуса коротких сообщений, необходимо
    отобрать небольшой процент тех, которые являются наиболее эмоциональными.
    В общем случае, можно сказать, что требуется функция, которая бы на основе
    слов сообщения, а также эмоциональных коэффициентов каждого из слов,
    позволила бы оценить рассматриваемое предложение.

    Вычисление эмоциональных коэффициентов можно производить
    с использованием лексиконов, на основе подхода, рассмотренного в п. \ref{sec:soEvaluation}.
    Определение оценки сообщения можно произвести одним из следующих способов:
    \begin{itemize}
        \item Вычисление {\it суммы эмоциональных коэффициентов} всех входящих в сообщение слов;
        \item Вычисление {\it максимального коэффициента} среди всех слов сообщения.
    \end{itemize}

    Если полученные значения рассматривать в формате абсолютных величин, то
    введение нижнего порогового значения позволяет отобрать наиболее подходящие
    сообщения. Таким образом можно получить сообщения, которые являются
    наиболее предпочтительными для балансировки обучающих коллекций.
