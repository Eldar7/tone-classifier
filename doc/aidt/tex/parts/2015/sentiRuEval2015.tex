\section{Тестирование на коллекции SentiRuEval-2015}
\label{sec:sentirueval2015}

Качество работы подготовленных моделей оценивается на основе $F_1$ меры:
\begin{equation}
    \label{eq:fmeasure}
    F_1 = 2 \cdot \dfrac{P \cdot R}{P + R}
\end{equation}

Такая мера позволяет одновременно учитывать результаты следующих параметров
относительно некоторого класса:
\begin{itemize}
    \item Точность ({\bf P}recision) -- количество сообщений, которое
        классификатор правильно отнес к соответствующему классу по отношению ко
        всему объему сообщений определенных системой в этот класс;
    \item Полнота ({\bf R}ecall) -- число найденных сообщений, которые
        действительно принадлежат соответствующему классу относительно всех
        сообщений соответствующего класса.
\end{itemize}

% Про макро/микро -усреднения при переходе к нескольким классам.
В случае, когда необходимо оценить качество работы по метрике $F_1$ относительно
несколькик классов, то применяются усреднения меры.
Различают {\it микро-} и {\it макро-} усреднения.
Для вычисления усредненной $F_{1}$ меры определяются
параметры полноты и точности с соответствующим усреднением относительно
интересующих нас классов, которые, в свою очередь, вычисляются на основе
таблиц контингентности.

%
% Если что, то можно вставить
%

Мaкроусреднение придает одинаковый вес каждому из усредняемых классов, в то
время как при микроусреднении вес учитывается на основе числа документов в
классе.
При использовании $F_{1}$-макро смещение среднего значения будет производиться в
сторону того класса, для которого классификатор сработал лучше; в тоже время,
при использовании $F_{1}$-микро, смещение будет произведено в сторону наибольшего
класса. \cite{micromacromeasures}

В данной задаче нас интересует качество определения тональных твитов, т.е.
сообщений соответсвующих положительному ({\it Positive}) и отрицательному
({\it Negative}) классам.
Будем рассматривать результаты с макроусреднением\footnote{
    [Код скрипта для вычисления]
} (формула \ref{eq:fmacro12})

\begin{equation}
    \label{eq:fmacro12}
    F_{1-macro}^{PN} = \dfrac{2 \cdot P_{macro_{(1,\ldots, N)}} R_{macro_{(1,\ldots, N)}} }{P_{macro_{(1,\ldots, N)}} + R_{macro_{(1,\ldots, N)}}}
\end{equation}

В тестировании участвуют прогоны с настройками, представленными в таблице
\ref{table:settings}.

\input{parts/2015/tables/settings}

Рассмотрим изменение результатов в каждом из прогонов для каждой задачи
(BANK, TKK), в зависимости от типа используемой обучающей коллекции.
Оценка качества работы классификаторов производится по метрике
$F_{1(macro)}^{PN}$.
Результаты приведены в таблице
\ref{table:results2015}.

\input{parts/2015/tables/results}
% Вывод о преимуществе применения балансировки.

Весьма неоднозначная картина поведения классификатора наблюдается в зависимости
от рассматриваемой задачи.
Интересно отметить, что сбалансированная коллекция улучшает результат для
задачи BANK (средний прирост $+3.02$), в то время как для классификации
коллекции задачи TCC, наоборот, лучше подходит использование несбалансированной
коллекции.

В остальном, добавление признаков (в том числе и на основе лексиконов)
стабильно улучшает качество работы классификатора.
Наибольший эффект улучшения наблюдается при вычислении
{\it минимума } и {\it максимума} (прогон №6, таблица \ref{table:results2015}).
% Благодаря введению таких признаков удалось добиться повышения качетва в среднем
% на \

Твиты коллекции TCC классифицируются несколько лучше, и аналогичная особенность
отмечается в \cite{tonalityAnalysis} что объясняется ухудшением ситуации на
Украине в период сбора сообщений для тестовой коллекции задачи BANK.
Так, например слово <<санкции>> может нести негативный характер в тестовой
выборке, в то время как в обучающей колекции аналогичное слово является
нейтральным.
