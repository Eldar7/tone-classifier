\section{Тестирование на коллекции SentiRuEval-2015}
\label{sec:sentirueval2015}

Качество работы подготовленных моделей оценивается на основе $F_1$ меры:
\begin{equation}
    \label{eq:fmeasure}
    F_1 = 2 \cdot \dfrac{P \cdot R}{P + R}
\end{equation}

Такая мера позволяет одновременно учитывать результаты следующих параметров
относительно некоторого класса:
\begin{itemize}
    \item Точность ({\bf P}recision) -- количество сообщений, которое
        классификатор правильно отнес к соответствующему классу по отношению ко
        всему объему сообщений определенных системой в этот класс;
    \item Полнота ({\bf R}ecall) -- число найденных сообщений, которые
        действительно принадлежат соответствующему классу относительно всех
        сообщений соответствующего класса.
\end{itemize}

% Про макро/микро -усреднения при переходе к нескольким классам.
В случае, когда необходимо оценить качество работы по метрике $F_1$ относительно
несколькик классов, то применяются усреднения меры.
Различают {\it микро-} и {\it макро-} усреднения.
Для вычисления усредненной $F_{1}$ меры определяются
параметры полноты и точности с соответствующим усреднением относительно
интересующих нас классов, которые, в свою очередь, вычисляются на основе
таблиц контингентности.

%
% Если что, то можно вставить
%

Мaкроусреднение придает одинаковый вес каждому из усредняемых классов, в то
время как при микроусреднении вес учитывается на основе числа документов в
классе.
При использовании $F_{1}$-макро смещение среднего значения будет производиться в
сторону того класса, для которого классификатор сработал лучше; в тоже время,
при использовании $F_{1}$-микро, смещение будет произведено в сторону наибольшего
класса. \cite{micromacromeasures}

В данной задаче нас интересует качество определения тональных твитов, т.е.
сообщений соответсвующих положительному ({\it Positive}) и отрицательному
({\it Negative}) классам.
Будем рассматривать результаты с макроусреднением $F_1$ меры\footnote{
    [Код скрипта для вычисления]
} (формула \ref{eq:fmacro12}).

\begin{equation}
    \label{eq:fmacro12}
    F_{1-macro}^{PN} = 2 \cdot \dfrac{P_{macro}^{PN} \cdot
        R_{macro}^{PN}}{P_{macro}^{PN} + R_{macro}^{PN}}
\end{equation}

В тестировании участвуют прогоны с настройками, представленными в таблице
\ref{table:settings}.
Все прогоны будут одновременно протестированы в двух областях:
\begin{itemize}
    \item BANK -- отзывы о банках;
    \item TCC -- отзывы о телекоммуникационных компаниях.
\end{itemize}

\input{parts/2015/tables/settings}

Рассмотрим качество работы классификационных моделей каждого из прогонов для
коллекций $BANK_{15}$ и $TCC_{15}$ в зависимости от типа обучающей коллекции.
Результаты проведенного тестирования зафиксированы в таблице \ref{table:results2015}.

\input{parts/2015/tables/results}
% Вывод о преимуществе применения балансировки.

Независимо от типа тестируемой коллекции, исходя из полученных результатов,
можно сказать что добавление признаков на основе лексиконов стабильно
повышает качество классификации.
Так, начиная с прогона №3 наблюдается прирост качества (см. результаты
прогонов с №3 -- №6, таблица \ref{table:results2015}.
Таким образом, заявленный прирост качества в статье близкого подхода
\cite{modernApproach} можно наблюдать и в тональной классификации русскоязычного
Твиттера.

Наибольший результат достигается в прогоне №6, где по каждому из лексиконов таблицы
\ref{table:createdLexicons} вычисляются все признаки: сумма, минимум и максимум.
Добавление последних двух признаков в векторизацию сообщений изменило
результат качества на +2.25 для $BANK_{15}$, и на +1.02 для $TKK_{15}$, если
сравнивать с подходом №5.

Если проанализировать результат с точки зрения влияния балансировки, то
здесь она приходится кстати, если говорить о коллекции $BANK_{15}$.
Средний прирост по каждому прогону, при сравнении результатов $I_{bank}^{15}$
с $B_{bank}^{15}$ составил +3.02.

Твиты коллекции TCC классифицируются несколько лучше. Эта особенность
отмечается в \cite{tonalityAnalysis} что объясняется ухудшением ситуации на
Украине в период сбора сообщений для тестовой коллекции $BANK_{15}$.
Так, например слово <<санкции>> может нести негативный характер в тестовой
выборке, в то время как в обучающей колекции аналогичное слово является
нейтральным.

Если сравнивать полученные результаты с участниками соревнований\footnote{
    Результаты участников соревнований SentiRuEval-2015:
    \url{https://docs.google.com/spreadsheets/d/1IxGFhGO4zS5t356FePIMdJQ5IU6-tkpetoOzoXpGLPs/edit\#gid=0}
},
то наилучший результат по метрике $F_{1-macro}^{PN}$ на коллекции $BANK_{15}$
составляет 35.98, а для коллекции $TCC_{15}$ -- 48.04.
Таким образом, текущий подход мог бы показать первое место на прошедших
соревнованиях {\it SentiRuEval-2015}.
Единственный нюанс -- необходимо было бы использовать данные для составления
лексиконов, собранные до даты проведения соревнования.
Но тем не менее, сравнивая лучший резульатат соревнования с прогоном №6
(см. таблицу \ref{table:results2015}), прирост относительно победителя
соревнований составляет +6.23 для задачи BANK, и +2.08 для задачи TCC.
